\documentclass[a4paper, 12pt]{book}

\input{preambule.tex}
\input{cover/preambule-garde.tex}

\documentname{Information theory}{Nicolas \textsc{Cerf}}{cover/cover_picture_infoh422.png}
\author{Sami \textsc{Abdul Sater}}


\usepackage[english]{babel}

\begin{document}

% Page de garde
\input{cover/pagedegarde.tex}

%% Insérer une citation

% Table des matières
\tableofcontents
\chapter{Introduction}
\section{Fundamental goals, questions, and operations}
\subsection{Highest achievable data compression}
\subsection{Highest achievable data send rate through channel}
\section{Overview of the course}

\section{First theorem : source coding theorem}
\subsection{Definition of entropy}
\subsection{Example}
\subsection{Block coding}

\section{Second theorem : channel coding theorem}
\subsection{Definition of capacity}
\subsection{Example}



\chapter{Overview of Shannon's entropy}
\section{Probabilities prerequisite}


\section{Entropy}
\subsection{Units}
\subsection{Examples}
\subsection{Remarks}
\subsection{Link with uncertainty : axiomatic approach}
\subsection{Interpretation of $H$}
\subsubsection{Special case : Bernoulli variable}
\subsubsection{Concavity of $H$}

\section{Joint entropy}

\section{Conditional entropy}
\subsection{Definition}
\subsection{Chain rule}
\subsection{Examples}
\subsection{Illustration : entropy Venn diagrams, link with mutual entropy}

\section{Mutual entropy}
\subsection{Formal definition of mutual entropy}

\section{Relative entropy}
\subsection{Definition}
\subsection{Conditional relative entropy}
\subsection{Chain rule for relative entropy}
\subsection{Fundamental information theorem}
\subsubsection{Corollary 1}
\subsubsection{Corollary 2}
% \subsection{Subadditivity of entropy} --> add as an additional property
\subsubsection{Corollary 3}
% \subsubsection{Example}
\subsubsection{Corollary 4}

\section{Entropy of multipartide systems}
\subsection{Chain rule for entropy}
\subsection{Chain rule for information}
\end{document}